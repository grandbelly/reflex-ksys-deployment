"""
Forecast Service - Online prediction data retrieval for Forecast Player UI.

This service provides read-only access to predictions generated by ForecastScheduler:
- Deployed model metadata
- Online predictions with confidence intervals
- Forecast step navigation (playback mode)
- Rolling window 23-point data structure (Canvas chart rendering)

NOTE: Model training and prediction generation happens in:
- ksys_app/ml/training_pipeline.py (training)
- ksys_app/schedulers/forecast_scheduler.py (online predictions)
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from zoneinfo import ZoneInfo

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

logger = logging.getLogger(__name__)


class ForecastService:
    """Service for retrieving online forecast predictions from database."""

    def __init__(self, session: AsyncSession):
        """
        Initialize forecast service.

        Args:
            session: AsyncSession for database operations
        """
        self.session = session

    # =========================================================================
    # FORECAST PLAYER METHODS - REALTIME MODE
    # =========================================================================

    async def get_deployed_models(self) -> List[Dict]:
        """
        Get list of deployed models with metadata and performance metrics.

        Returns:
            List of dicts with:
                - model_id
                - model_name
                - model_type
                - tag_name
                - version
                - deployed_at
                - validation_mae
                - validation_mape
                - validation_rmse
                - pipeline_config (for extracting horizons)
                - prediction_count (number of predictions generated)
                - last_forecast_time (most recent prediction timestamp)
        """
        query = text("""
            SELECT
                mr.model_id,
                mr.model_name,
                mr.model_type,
                mr.tag_name,
                mr.version,
                mr.deployed_at AT TIME ZONE 'Asia/Seoul' as deployed_at_kst,
                ROUND(mr.validation_mae::numeric, 2) as mae,
                ROUND(mr.validation_mape::numeric, 2) as mape,
                ROUND(mr.validation_rmse::numeric, 2) as rmse,
                mr.pipeline_config,
                COUNT(p.prediction_id) as prediction_count,
                MAX(p.forecast_time AT TIME ZONE 'Asia/Seoul') as last_forecast_time
            FROM model_registry mr
            LEFT JOIN predictions p ON mr.model_id = p.model_id
            WHERE mr.is_deployed = true
            GROUP BY mr.model_id, mr.model_name, mr.model_type, mr.tag_name,
                     mr.version, mr.deployed_at, mr.validation_mae, mr.validation_mape, mr.validation_rmse, mr.pipeline_config
            ORDER BY mr.deployed_at DESC, mr.model_id DESC
        """)

        result = await self.session.execute(query)
        rows = result.mappings().all()

        return [
            {
                "model_id": r["model_id"],
                "model_name": r["model_name"],
                "model_type": r["model_type"],
                "tag_name": r["tag_name"],
                "version": r["version"],
                "deployed_at": r["deployed_at_kst"].isoformat() if r["deployed_at_kst"] else None,
                "mae": float(r["mae"]) if r["mae"] else None,
                "mape": float(r["mape"]) if r["mape"] else None,
                "rmse": float(r["rmse"]) if r["rmse"] else None,
                "pipeline_config": r["pipeline_config"],
                "prediction_count": r["prediction_count"],
                "last_forecast_time": r["last_forecast_time"].isoformat() if r["last_forecast_time"] else None,
            }
            for r in rows
        ]

    async def get_predictions(
        self,
        model_id: Optional[int] = None,
        tag_name: Optional[str] = None,
        hours_ahead: int = 24,
    ) -> List[Dict]:
        """
        Get online predictions from deployed models (for table display).

        Args:
            model_id: Filter by specific model ID
            tag_name: Filter by sensor tag name
            hours_ahead: Number of hours ahead to retrieve predictions (default 24)

        Returns:
            List of dicts with:
                - prediction_id
                - forecast_time (when prediction was made)
                - target_time (when prediction is for)
                - horizon_minutes
                - horizon_hours
                - predicted_value
                - actual_value (if available)
                - prediction_error (if actual available)
                - absolute_percentage_error (if actual available)
                - ci_lower (confidence interval lower bound)
                - ci_upper (confidence interval upper bound)
                - has_actual (whether actual value is available)
                - forecast_time_display (KST string)
                - target_time_display (KST string)
        """
        # Build WHERE clause
        where_clauses = []
        params = {}

        if model_id:
            where_clauses.append("p.model_id = :model_id")
            params["model_id"] = model_id

        if tag_name:
            where_clauses.append("p.tag_name = :tag_name")
            params["tag_name"] = tag_name

        # Get predictions up to hours_ahead from now
        where_clauses.append("p.target_time <= CURRENT_TIMESTAMP + make_interval(hours => :hours_ahead)")
        params["hours_ahead"] = hours_ahead

        where_sql = " AND ".join(where_clauses) if where_clauses else "1=1"

        query = text(f"""
            SELECT
                p.prediction_id,
                p.forecast_time AT TIME ZONE 'Asia/Seoul' as forecast_time_kst,
                p.target_time AT TIME ZONE 'Asia/Seoul' as target_time_kst,
                p.horizon_minutes,
                ROUND((p.horizon_minutes::numeric / 60), 1) as horizon_hours,
                ROUND(p.predicted_value::numeric, 2) as predicted_value,
                ROUND(p.actual_value::numeric, 2) as actual_value,
                ROUND(p.prediction_error::numeric, 2) as prediction_error,
                ROUND(p.absolute_percentage_error::numeric, 2) as absolute_percentage_error,
                ROUND(p.ci_lower::numeric, 2) as ci_lower,
                ROUND(p.ci_upper::numeric, 2) as ci_upper,
                p.tag_name,
                p.model_id,
                CASE WHEN p.actual_value IS NOT NULL THEN true ELSE false END as has_actual,
                TO_CHAR(p.forecast_time AT TIME ZONE 'Asia/Seoul', 'YYYY-MM-DD HH24:MI') as forecast_time_display,
                TO_CHAR(p.target_time AT TIME ZONE 'Asia/Seoul', 'MM-DD HH24:MI') as target_time_display
            FROM predictions p
            WHERE {where_sql}
            ORDER BY p.horizon_minutes ASC, p.target_time ASC
            LIMIT 1000
        """)

        result = await self.session.execute(query, params)
        rows = result.mappings().all()

        return [
            {
                "prediction_id": r["prediction_id"],
                "forecast_time": r["forecast_time_kst"].isoformat() if r["forecast_time_kst"] else None,
                "target_time": r["target_time_kst"].isoformat() if r["target_time_kst"] else None,
                "horizon_minutes": r["horizon_minutes"],
                "horizon_hours": float(r["horizon_hours"]) if r["horizon_hours"] else 0.0,
                "predicted_value": float(r["predicted_value"]) if r["predicted_value"] else 0.0,
                "actual_value": float(r["actual_value"]) if r["actual_value"] else None,
                "prediction_error": float(r["prediction_error"]) if r["prediction_error"] else None,
                "absolute_percentage_error": float(r["absolute_percentage_error"]) if r["absolute_percentage_error"] else None,
                "ci_lower": float(r["ci_lower"]) if r["ci_lower"] else None,
                "ci_upper": float(r["ci_upper"]) if r["ci_upper"] else None,
                "tag_name": r["tag_name"],
                "model_id": r["model_id"],
                "has_actual": r["has_actual"],
                "forecast_time_display": r["forecast_time_display"],
                "target_time_display": r["target_time_display"],
            }
            for r in rows
        ]

    async def get_latest_sensor_value(self, tag_name: str) -> Optional[Dict]:
        """
        Get latest actual sensor value for comparison with predictions.

        Args:
            tag_name: Sensor tag name

        Returns:
            Dict with:
                - tag_name
                - value
                - timestamp (KST)
                - quality
        """
        query = text("""
            SELECT
                tag_name,
                ROUND(value::numeric, 2) as value,
                ts AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                quality
            FROM influx_latest
            WHERE tag_name = :tag_name
            LIMIT 1
        """)

        result = await self.session.execute(query, {"tag_name": tag_name})
        row = result.mappings().first()

        if not row:
            return None

        return {
            "tag_name": row["tag_name"],
            "value": float(row["value"]) if row["value"] else 0.0,
            "timestamp": row["timestamp_kst"].isoformat() if row["timestamp_kst"] else None,
            "quality": row["quality"],
        }

    async def get_rolling_window_data(
        self,
        model_id: int,
        lookback_intervals: int = 30,  # ✅ FIX: 30 past intervals for 67 total points (30 + 1 + 36)
    ) -> List[Dict]:
        """
        Get Rolling Window data structure for Canvas chart rendering.

        ✅ DYNAMIC implementation based on actual model horizons.

        Structure:
        - Past N timepoints: Actual sensor values (lookback_intervals개)
        - Present 1 timepoint (T0): Current moment (red reference line)
        - Future M timepoints: Predictions (model의 실제 horizon 개수만큼)

        Total: N + 1 + M points (동적으로 구성)

        Example for Model 67:
        - Past 10: T-10, T-9, ..., T-1
        - Present 1: T0
        - Future 36: T+1, T+2, ..., T+36 (horizons: 10, 20, 30...360분)
        - Total: 47 points

        Args:
            model_id: Deployed model ID
            lookback_intervals: Number of past intervals to show (default 10)

        Returns:
            List of dicts with:
                - time_label: "T-10", "T-9", ..., "T0", "T+1", ..., "T+36"
                - timestamp: ISO timestamp (KST)
                - time_display: "HH:MM" format for display
                - actual_value: Actual sensor value (Past + Present only)
                - predicted_value: Predicted value (Future only)
                - ci_lower: Lower 95% CI (Future only)
                - ci_upper: Upper 95% CI (Future only)
                - zone: "past" | "present" | "future"
                - horizon_minutes: Horizon in minutes (Future only)
        """
        kst = ZoneInfo("Asia/Seoul")
        now = datetime.now(kst)

        # Get tag name and horizons from model
        model_query = text("""
            SELECT tag_name, pipeline_config
            FROM model_registry
            WHERE model_id = :model_id
        """)
        model_result = await self.session.execute(model_query, {"model_id": model_id})
        model_row = model_result.mappings().first()
        if not model_row:
            raise ValueError(f"Model {model_id} not found")

        tag_name = model_row["tag_name"]
        pipeline_config = model_row["pipeline_config"]

        # Extract horizons from pipeline_config
        import json
        if isinstance(pipeline_config, str):
            pipeline_config = json.loads(pipeline_config)

        forecast_config = pipeline_config.get("forecast_config", {})
        horizons = forecast_config.get("horizons", [])

        if not horizons:
            raise ValueError(f"Model {model_id} has no horizons configured")

        # Determine interval from horizons (assume uniform spacing)
        if len(horizons) >= 2:
            interval_minutes = horizons[1] - horizons[0]
        else:
            interval_minutes = horizons[0]

        # ✅ FIX: Use latest forecast_time from predictions table as T0
        # This shows the most recent predictions, even if sensor data is delayed
        latest_ts_query = text("""
            SELECT MAX(forecast_time) AT TIME ZONE 'Asia/Seoul' as latest_ts
            FROM predictions
            WHERE model_id = :model_id
        """)
        latest_ts_result = await self.session.execute(latest_ts_query, {"model_id": model_id})
        latest_ts_row = latest_ts_result.mappings().first()

        if latest_ts_row and latest_ts_row["latest_ts"]:
            # Use latest forecast_time as reference point (T0)
            reference_time = latest_ts_row["latest_ts"]
        else:
            # Fallback to NOW if no predictions found
            reference_time = now

        # Build timeline BASED ON reference_time (not NOW!)
        points = []
        past_start_minutes = -lookback_intervals * interval_minutes

        # PAST N points (lookback_intervals개)
        for i in range(-lookback_intervals, 0):
            ts = reference_time + timedelta(minutes=i * interval_minutes)
            time_str = ts.strftime("%H:%M")
            points.append({
                "time_label": f"T{i}\n{time_str}",  # Combined label with timestamp
                "timestamp": ts.isoformat(),
                "time_display": time_str,
                "zone": "past",
                "target_offset_minutes": i * interval_minutes,
            })

        # PRESENT 1 point (T0) - reference_time
        time_str = reference_time.strftime("%H:%M")
        points.append({
            "time_label": f"T0\n{time_str}",  # Combined label with timestamp
            "timestamp": reference_time.isoformat(),
            "time_display": time_str,
            "zone": "present",
            "target_offset_minutes": 0,
        })

        # FUTURE M points (horizons 개수만큼) - from reference_time
        for idx, horizon in enumerate(horizons, start=1):
            ts = reference_time + timedelta(minutes=horizon)
            time_str = ts.strftime("%H:%M")
            points.append({
                "time_label": f"T+{idx}\n{time_str}",  # Combined label with timestamp
                "timestamp": ts.isoformat(),
                "time_display": time_str,
                "zone": "future",
                "target_offset_minutes": horizon,
                "horizon_minutes": horizon,
            })

        # Fetch actual values for PAST + PRESENT (around reference_time)
        past_start = reference_time + timedelta(minutes=past_start_minutes)
        past_end = reference_time

        # ✅ Use influx_agg_10m for stable 10-minute boundaries
        actual_query = text("""
            SELECT
                bucket AT TIME ZONE 'Asia/Seoul' as ts,
                ROUND(avg::numeric, 2) as val
            FROM influx_agg_10m
            WHERE tag_name = :tag
                AND bucket >= :start
                AND bucket <= :end
            ORDER BY bucket ASC
        """)

        actual_result = await self.session.execute(actual_query, {
            "tag": tag_name,
            "start": past_start,
            "end": past_end,
        })
        actual_rows = actual_result.mappings().all()

        # Map actual values to time points (find nearest timestamp within tolerance)
        actual_dict = {}
        for row in actual_rows:
            ts = row["ts"]
            value = float(row["val"]) if row["val"] else None
            if ts and value is not None:
                actual_dict[ts] = value

        # Match actual values to past/present points
        tolerance = timedelta(minutes=interval_minutes // 2 + 1)
        for point in points:
            if point["zone"] in ["past", "present"]:
                target_ts_str = point["timestamp"]
                # Parse as timezone-aware (KST)
                target_ts = datetime.fromisoformat(target_ts_str)
                if target_ts.tzinfo is None:
                    target_ts = target_ts.replace(tzinfo=kst)

                # Find closest actual value within tolerance
                closest_val = None
                min_delta = timedelta(days=1)  # Start beyond any reasonable tolerance

                for ts, val in actual_dict.items():
                    # Ensure ts is timezone-aware
                    if ts.tzinfo is None:
                        ts = ts.replace(tzinfo=kst)
                    delta = abs(ts - target_ts)
                    if delta < min_delta:
                        min_delta = delta
                        closest_val = val

                point["actual_value"] = closest_val if min_delta <= tolerance else None

        # ✅ Match past predictions to past/present points
        # Get all historical predictions that have target_time matching past/present timeline
        past_pred_query = text("""
            SELECT
                target_time AT TIME ZONE 'Asia/Seoul' as target_ts,
                ROUND(predicted_value::numeric, 2) as pred_val,
                forecast_time AT TIME ZONE 'Asia/Seoul' as fc_time
            FROM predictions
            WHERE model_id = :model_id
                AND target_time >= :past_start
                AND target_time <= :past_end
            ORDER BY target_time ASC, forecast_time DESC
        """)

        past_pred_result = await self.session.execute(past_pred_query, {
            "model_id": model_id,
            "past_start": past_start,
            "past_end": past_end,
        })
        past_pred_rows = past_pred_result.mappings().all()

        # Build dict: target_time → predicted_value (use most recent forecast_time)
        past_pred_dict = {}
        for row in past_pred_rows:
            target_ts = row["target_ts"]
            pred_val = float(row["pred_val"]) if row["pred_val"] else None
            # Only keep the first one (most recent forecast_time due to ORDER BY DESC)
            if target_ts not in past_pred_dict:
                past_pred_dict[target_ts] = pred_val

        # Match past predictions to past/present points
        for point in points:
            if point["zone"] in ["past", "present"]:
                target_ts_str = point["timestamp"]
                target_ts = datetime.fromisoformat(target_ts_str)
                if target_ts.tzinfo is None:
                    target_ts = target_ts.replace(tzinfo=kst)

                # Find closest predicted value within tolerance
                closest_pred = None
                min_delta = timedelta(days=1)

                for ts, pred_val in past_pred_dict.items():
                    if ts.tzinfo is None:
                        ts = ts.replace(tzinfo=kst)
                    delta = abs(ts - target_ts)
                    if delta < min_delta:
                        min_delta = delta
                        closest_pred = pred_val

                point["predicted_value"] = closest_pred if min_delta <= tolerance else None

        # Fetch predictions for FUTURE (모든 horizons) + actual values if available
        latest_forecast_query = text("""
            SELECT MAX(forecast_time) as latest_ft
            FROM predictions
            WHERE model_id = :model_id
        """)
        latest_ft_result = await self.session.execute(latest_forecast_query, {"model_id": model_id})
        latest_ft_row = latest_ft_result.mappings().first()

        if latest_ft_row and latest_ft_row["latest_ft"]:
            latest_forecast_time = latest_ft_row["latest_ft"]

            pred_query = text("""
                SELECT
                    horizon_minutes,
                    target_time AT TIME ZONE 'Asia/Seoul' as ts,
                    ROUND(predicted_value::numeric, 2) as pred,
                    ROUND(actual_value::numeric, 2) as actual,
                    ROUND(ci_lower::numeric, 2) as ci_lo,
                    ROUND(ci_upper::numeric, 2) as ci_hi
                FROM predictions
                WHERE model_id = :model_id
                    AND forecast_time = :forecast_time
                ORDER BY horizon_minutes ASC
            """)

            pred_result = await self.session.execute(pred_query, {
                "model_id": model_id,
                "forecast_time": latest_forecast_time,
            })
            pred_rows = pred_result.mappings().all()

            # Map predictions to future points by horizon
            pred_dict = {}
            for row in pred_rows:
                horizon = row["horizon_minutes"]
                pred_dict[horizon] = {
                    "predicted_value": float(row["pred"]) if row["pred"] else None,
                    "actual_value": float(row["actual"]) if row["actual"] else None,  # ✅ Include actual value from predictions table
                    "ci_lower": float(row["ci_lo"]) if row["ci_lo"] else None,
                    "ci_upper": float(row["ci_hi"]) if row["ci_hi"] else None,
                }

            # Match predictions to future points
            for point in points:
                if point["zone"] == "future":
                    horizon = point.get("horizon_minutes")
                    if horizon and horizon in pred_dict:
                        point.update(pred_dict[horizon])

        return points

    # =========================================================================
    # DEPRECATED - Will be removed after Realtime chart switches to 23-point
    # =========================================================================

    async def get_predictions_grouped(
        self,
        model_id: Optional[int] = None,
        tag_name: Optional[str] = None,
        hours_ahead: int = 24,
        representative_horizons: Optional[List[int]] = None,
    ) -> List[Dict]:
        """
        ⚠️ DEPRECATED - Use get_rolling_window_23_points() instead.

        Get predictions for Realtime mode with multiple horizon lines.
        This creates incorrect visualization with dynamic horizon selection.

        Args:
            model_id: Filter by specific model ID
            tag_name: Filter by sensor tag name
            hours_ahead: Number of hours ahead to retrieve predictions
            representative_horizons: List of horizon minutes to display (e.g., [10, 70, 180, 300, 360])

        Returns:
            List of dicts with timeline data (INCORRECT STRUCTURE)
        """
        # Build WHERE clause
        where_clauses = []
        params = {}

        if model_id:
            where_clauses.append("p.model_id = :model_id")
            params["model_id"] = model_id

        if tag_name:
            where_clauses.append("p.tag_name = :tag_name")
            params["tag_name"] = tag_name

        where_sql = " AND ".join(where_clauses) if where_clauses else "1=1"

        # Get latest forecast_time and tag_name
        latest_query = text(f"""
            SELECT
                MAX(forecast_time) as latest_forecast_time,
                MAX(tag_name) as tag_name
            FROM predictions p
            WHERE {where_sql}
        """)
        latest_result = await self.session.execute(latest_query, params)
        latest_row = latest_result.mappings().first()

        if not latest_row or not latest_row["latest_forecast_time"]:
            return []

        forecast_time = latest_row["latest_forecast_time"]
        resolved_tag_name = tag_name or latest_row["tag_name"]

        # Get historical actual data (24 hours before forecast_time)
        lookback_hours = 24
        history_start = forecast_time - timedelta(hours=lookback_hours)

        actual_query = text("""
            SELECT
                ts AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                TO_CHAR(ts AT TIME ZONE 'Asia/Seoul', 'MM-DD HH24:MI') as time_display,
                ROUND(value::numeric, 2) as actual_value
            FROM influx_hist
            WHERE tag_name = :tag_name
                AND ts >= :start_time
                AND ts < :forecast_time
                AND quality IN (0, 192)
            ORDER BY ts ASC
        """)

        actual_result = await self.session.execute(
            actual_query,
            {
                "tag_name": resolved_tag_name,
                "start_time": history_start,
                "forecast_time": forecast_time,
            }
        )
        actual_rows = actual_result.mappings().all()

        # Get predictions for representative horizons
        if representative_horizons:
            horizon_filter = "AND p.horizon_minutes = ANY(:horizons)"
            params["horizons"] = representative_horizons
        else:
            horizon_filter = ""

        pred_query = text(f"""
            SELECT
                p.target_time AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                TO_CHAR(p.target_time AT TIME ZONE 'Asia/Seoul', 'MM-DD HH24:MI') as time_display,
                p.horizon_minutes,
                ROUND(p.predicted_value::numeric, 2) as predicted_value,
                ROUND(p.ci_lower::numeric, 2) as ci_lower,
                ROUND(p.ci_upper::numeric, 2) as ci_upper,
                ROUND(p.actual_value::numeric, 2) as actual_value
            FROM predictions p
            WHERE {where_sql}
                AND p.forecast_time = :forecast_time
                {horizon_filter}
            ORDER BY p.target_time ASC, p.horizon_minutes ASC
        """)

        pred_result = await self.session.execute(
            pred_query,
            {**params, "forecast_time": forecast_time}
        )
        pred_rows = pred_result.mappings().all()

        # Get latest sensor value for reference line
        latest_value = None
        if resolved_tag_name:
            latest = await self.get_latest_sensor_value(resolved_tag_name)
            if latest:
                latest_value = latest.get("value")

        # Build chart data structure
        chart_data = {}

        # Add historical actual data (PAST zone)
        for row in actual_rows:
            ts_iso = row["timestamp_kst"].isoformat() if row["timestamp_kst"] else None
            if ts_iso:
                chart_data[ts_iso] = {
                    "time": row["time_display"],
                    "timestamp": ts_iso,
                    "actual": float(row["actual_value"]) if row["actual_value"] else None,
                }

        # Add forecast_time as the PRESENT moment
        forecast_time_kst = forecast_time.astimezone(ZoneInfo("Asia/Seoul"))
        forecast_ts_iso = forecast_time_kst.isoformat()
        if forecast_ts_iso not in chart_data:
            chart_data[forecast_ts_iso] = {
                "time": forecast_time_kst.strftime("%m-%d %H:%M"),
                "timestamp": forecast_ts_iso,
                "actual": None,
            }

        # Add predictions (FUTURE zone) - each horizon as separate column
        for row in pred_rows:
            ts_iso = row["timestamp_kst"].isoformat() if row["timestamp_kst"] else None
            if not ts_iso:
                continue

            if ts_iso not in chart_data:
                chart_data[ts_iso] = {
                    "time": row["time_display"],
                    "timestamp": ts_iso,
                    "actual": float(row["actual_value"]) if row["actual_value"] else None,
                }

            # Add prediction for this horizon
            horizon_key = f"pred_{row['horizon_minutes']}min"
            ci_lower_key = f"ci_lower_{row['horizon_minutes']}min"
            ci_upper_key = f"ci_upper_{row['horizon_minutes']}min"

            chart_data[ts_iso][horizon_key] = float(row["predicted_value"]) if row["predicted_value"] else None
            chart_data[ts_iso][ci_lower_key] = float(row["ci_lower"]) if row["ci_lower"] else None
            chart_data[ts_iso][ci_upper_key] = float(row["ci_upper"]) if row["ci_upper"] else None

        # Convert to list and add current reference value
        result = []
        for ts_iso in sorted(chart_data.keys()):
            row_dict = chart_data[ts_iso]
            if latest_value is not None:
                row_dict["current"] = latest_value
            result.append(row_dict)

        return result

    # =========================================================================
    # FORECAST PLAYER METHODS - PLAYBACK MODE
    # =========================================================================

    async def get_forecast_steps(self, model_id: int) -> List[Dict]:
        """
        Get all distinct forecast steps (forecast_time) for a model.
        Each step represents one complete forecast run.

        Args:
            model_id: Model ID to get steps for

        Returns:
            List of dicts with:
                - step_number (1-indexed)
                - forecast_time (when forecast was generated)
                - forecast_time_kst (KST ISO string)
                - prediction_count (number of predictions in this step)
        """
        query = text("""
            WITH step_times AS (
                SELECT DISTINCT
                    forecast_time,
                    forecast_time AT TIME ZONE 'Asia/Seoul' as forecast_time_kst,
                    COUNT(*) OVER (PARTITION BY forecast_time) as prediction_count
                FROM predictions
                WHERE model_id = :model_id
                ORDER BY forecast_time ASC
            )
            SELECT
                ROW_NUMBER() OVER (ORDER BY forecast_time ASC) as step_number,
                forecast_time,
                forecast_time_kst,
                prediction_count
            FROM step_times
            ORDER BY forecast_time ASC
        """)

        result = await self.session.execute(query, {"model_id": model_id})
        rows = result.mappings().all()

        return [
            {
                "step_number": r["step_number"],
                "forecast_time": r["forecast_time"].isoformat() if r["forecast_time"] else None,
                "forecast_time_kst": r["forecast_time_kst"].isoformat() if r["forecast_time_kst"] else None,
                "prediction_count": r["prediction_count"],
            }
            for r in rows
        ]

    async def get_step_data(
        self,
        model_id: int,
        forecast_time: str,
        lookback_days: int = 7,
    ) -> Dict:
        """
        Get combined actual + forecast data for a specific forecast step.
        This creates the timeline visualization with actual history and forecast overlay.

        Args:
            model_id: Model ID
            forecast_time: ISO timestamp of the forecast step
            lookback_days: Days of historical data to include before forecast

        Returns:
            Dict with:
                - forecast_time: ISO string
                - actual_data: List of historical actual values
                - forecast_data: List of predictions for this step
                - tag_name: Sensor tag name
        """
        # Parse forecast_time
        forecast_dt = datetime.fromisoformat(forecast_time.replace('Z', '+00:00'))

        # Get tag name for this model
        tag_query = text("""
            SELECT tag_name
            FROM model_registry
            WHERE model_id = :model_id
            LIMIT 1
        """)
        tag_result = await self.session.execute(tag_query, {"model_id": model_id})
        tag_row = tag_result.mappings().first()

        if not tag_row:
            raise ValueError(f"Model {model_id} not found")

        tag_name = tag_row["tag_name"]

        # Get actual historical data (lookback_days before forecast_time)
        # AND actual data for the forecasted time period (for comparison)
        actual_query = text("""
            SELECT
                ts AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                ROUND(value::numeric, 2) as value,
                'actual' as data_type
            FROM influx_hist
            WHERE tag_name = :tag_name
                AND ts >= :start_time
                AND ts <= :end_time_extended
                AND quality IN (0, 192)
            ORDER BY ts ASC
        """)

        start_time = forecast_dt - timedelta(days=lookback_days)
        # Extend end time to include the forecasted period (up to 24 hours ahead)
        end_time_extended = forecast_dt + timedelta(hours=24)
        actual_result = await self.session.execute(
            actual_query,
            {
                "tag_name": tag_name,
                "start_time": start_time,
                "end_time_extended": end_time_extended,
            }
        )
        actual_rows = actual_result.mappings().all()

        # Get forecast predictions for this step
        forecast_query = text("""
            SELECT
                target_time AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                ROUND(predicted_value::numeric, 2) as value,
                ROUND((horizon_minutes::numeric / 60), 1) as horizon_hours,
                ROUND(ci_lower::numeric, 2) as ci_lower,
                ROUND(ci_upper::numeric, 2) as ci_upper,
                'forecast' as data_type
            FROM predictions
            WHERE model_id = :model_id
                AND forecast_time = :forecast_time
            ORDER BY target_time ASC
        """)

        forecast_result = await self.session.execute(
            forecast_query,
            {
                "model_id": model_id,
                "forecast_time": forecast_dt,
            }
        )
        forecast_rows = forecast_result.mappings().all()

        return {
            "forecast_time": forecast_dt.astimezone(ZoneInfo("Asia/Seoul")).isoformat(),
            "tag_name": tag_name,
            "actual_data": [
                {
                    "timestamp": r["timestamp_kst"].isoformat() if r["timestamp_kst"] else None,
                    "value": float(r["value"]) if r["value"] else 0.0,
                    "data_type": "actual",
                }
                for r in actual_rows
            ],
            "forecast_data": [
                {
                    "timestamp": r["timestamp_kst"].isoformat() if r["timestamp_kst"] else None,
                    "value": float(r["value"]) if r["value"] else 0.0,
                    "horizon_hours": float(r["horizon_hours"]) if r["horizon_hours"] else 0.0,
                    "ci_lower": float(r["ci_lower"]) if r["ci_lower"] else None,
                    "ci_upper": float(r["ci_upper"]) if r["ci_upper"] else None,
                    "data_type": "forecast",
                }
                for r in forecast_rows
            ],
        }

    async def get_timeline_chart_data(
        self,
        model_id: int,
        forecast_time: str,
        lookback_days: int = 7,
    ) -> List[Dict]:
        """
        Get combined actual + forecast data for timeline chart (chart-ready format).
        Uses SQL FULL OUTER JOIN to merge actual and forecast data.

        Args:
            model_id: Model ID
            forecast_time: ISO timestamp of the forecast step
            lookback_days: Days of historical data to include before forecast

        Returns:
            List of dicts with:
                - timestamp: ISO timestamp
                - actual: Actual value (if available)
                - forecast: Forecast value (if available)
                - ci_lower: Confidence interval lower bound
                - ci_upper: Confidence interval upper bound
                - horizon_hours: Prediction horizon in hours
                - error: Prediction error (if both actual and forecast exist)
                - data_type: "actual", "forecast", or "both"
        """
        # Parse forecast_time
        forecast_dt = datetime.fromisoformat(forecast_time.replace('Z', '+00:00'))

        # Get tag name for this model
        tag_query = text("""
            SELECT tag_name
            FROM model_registry
            WHERE model_id = :model_id
            LIMIT 1
        """)
        tag_result = await self.session.execute(tag_query, {"model_id": model_id})
        tag_row = tag_result.mappings().first()

        if not tag_row:
            raise ValueError(f"Model {model_id} not found")

        tag_name = tag_row["tag_name"]

        start_time = forecast_dt - timedelta(days=lookback_days)
        end_time_extended = forecast_dt + timedelta(hours=24)

        # SQL: Combine actual and forecast data with FULL OUTER JOIN
        query = text("""
            WITH actual_data AS (
                SELECT
                    ts AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                    ROUND(value::numeric, 2) as actual_value
                FROM influx_hist
                WHERE tag_name = :tag_name
                    AND ts >= :start_time
                    AND ts <= :end_time_extended
                    AND quality IN (0, 192)
            ),
            forecast_data AS (
                SELECT
                    target_time AT TIME ZONE 'Asia/Seoul' as timestamp_kst,
                    ROUND(predicted_value::numeric, 2) as forecast_value,
                    ROUND((horizon_minutes::numeric / 60), 1) as horizon_hours,
                    ROUND(ci_lower::numeric, 2) as ci_lower,
                    ROUND(ci_upper::numeric, 2) as ci_upper
                FROM predictions
                WHERE model_id = :model_id
                    AND forecast_time = :forecast_time
            )
            SELECT
                COALESCE(a.timestamp_kst, f.timestamp_kst) as timestamp_kst,
                a.actual_value,
                f.forecast_value,
                f.ci_lower,
                f.ci_upper,
                f.horizon_hours,
                CASE
                    WHEN a.actual_value IS NOT NULL AND f.forecast_value IS NOT NULL
                        THEN ROUND((f.forecast_value - a.actual_value)::numeric, 2)
                    ELSE NULL
                END as error,
                CASE
                    WHEN a.actual_value IS NOT NULL AND f.forecast_value IS NOT NULL THEN 'both'
                    WHEN a.actual_value IS NOT NULL THEN 'actual'
                    WHEN f.forecast_value IS NOT NULL THEN 'forecast'
                    ELSE 'unknown'
                END as data_type
            FROM actual_data a
            FULL OUTER JOIN forecast_data f
                ON a.timestamp_kst = f.timestamp_kst
            ORDER BY COALESCE(a.timestamp_kst, f.timestamp_kst) ASC
        """)

        result = await self.session.execute(
            query,
            {
                "tag_name": tag_name,
                "start_time": start_time,
                "end_time_extended": end_time_extended,
                "model_id": model_id,
                "forecast_time": forecast_dt,
            }
        )
        rows = result.mappings().all()

        return [
            {
                "timestamp": r["timestamp_kst"].isoformat() if r["timestamp_kst"] else None,
                "actual": float(r["actual_value"]) if r["actual_value"] else None,
                "forecast": float(r["forecast_value"]) if r["forecast_value"] else None,
                "ci_lower": float(r["ci_lower"]) if r["ci_lower"] else None,
                "ci_upper": float(r["ci_upper"]) if r["ci_upper"] else None,
                "horizon_hours": float(r["horizon_hours"]) if r["horizon_hours"] else None,
                "error": float(r["error"]) if r["error"] else None,
                "data_type": r["data_type"],
            }
            for r in rows
        ]
